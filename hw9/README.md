# Performing Stochastic Gradient Descent
## AI 211 Coding Challenge 9

This code submission by Jan Lendl Uy comprises two files:

- Gradient_Descent.py
- Gradient_Descent_Tests.py

In `Gradient_Descent.py`, it contains the implementation for performing stochastic gradient descent. By default, batch size is set to one (1) for ease of implementation. You may check this file to inspect the implementation of the algorithm.

On the other hand, `Gradient_Descent_Tests.py` contains the tests performed in verifying the correctness of the stochastic gradient descent (SGD) implementation. Neural networks are trained with the XOR operation to check if the SGD algorithm converges to a satisfiable minimum (i.e. small loss values). RUN this file to check the results for different tests which include:

- 2-Layer Neural Network
- N-Layer Neural Network with Random Number of Neurons and Hidden Layer Depth